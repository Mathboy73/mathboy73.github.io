{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mathboy73/mathboy73.github.io/blob/main/grupo22_datathon2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510c6998",
      "metadata": {
        "id": "510c6998"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "import IPython\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import io\n",
        "import pandas as pd\n",
        "import time\n",
        "from statistics import median, mean\n",
        "from urllib.request import urlopen\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.fftpack import fft,ifft\n",
        "from scipy.io import wavfile # get the api\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "def play_audio_fragment(filename, start, end, samplerate = 50000):\n",
        "    \"\"\"Play a fragment of an audio file.\n",
        "    Args:\n",
        "        filename: path to the audio file\n",
        "        start: start of the fragment in samples\n",
        "        end: end of the fragment in samples\n",
        "        samplerate: samplerate to use when reading the file\"\"\"\n",
        "    if not filename.startswith(\".\"):\n",
        "        #filename = f\"https://storage.googleapis.com/datathon2022/dataset1/{filename}.ogg\"\n",
        "        prefix = \"./datathon2022\\\\datathon2022\\\\dataset1\\\\\"\n",
        "        filename = f\"{prefix+filename}.wav\"\n",
        "\n",
        "\n",
        "    #if filename.startswith(\"http\"):\n",
        "        #filename = io.BytesIO(urlopen(filename).read())\n",
        "\n",
        "    data, read_sr = sf.read(filename, start=start, stop=end)\n",
        "\n",
        "\n",
        "    assert samplerate == read_sr, f\"samplerate does not match {samplerate} (from file) != {read_sr} (function parameter)\"\n",
        "\n",
        "    IPython.display.display(IPython.display.Audio(data, rate=samplerate))\n",
        "def export_audio_fragment(filename, start, end, iviend, samplerate = 50000):\n",
        "    \"\"\"Play a fragment of an audio file.\n",
        "    Args:\n",
        "        filename: path to the audio file\n",
        "        start: start of the fragment in samples\n",
        "        end: end of the fragment in samples\n",
        "        samplerate: samplerate to use when reading the file\"\"\"\n",
        "    if not filename.startswith(\".\"):\n",
        "\n",
        "        prefix = \"./datathon2022\\\\datathon2022\\\\dataset1\\\\\"\n",
        "        filename = f\"{prefix+filename}.wav\"\n",
        "\n",
        "    #data, read_sr = sf.read(filename, start=start, stop=end)\n",
        "    data, read_sr = sf.read(filename)\n",
        "    start =int(np.ceil(start*read_sr))\n",
        "    end = int(np.ceil(iviend*read_sr))\n",
        "    #print(len(data))\n",
        "    #print(start,end)\n",
        "\n",
        "\n",
        "    assert samplerate == read_sr, f\"samplerate does not match {samplerate} (from file) != {read_sr} (function parameter)\"\n",
        "    data = data[start:end]\n",
        "    #IPython.display.display(IPython.display.Audio(data, rate=samplerate))\n",
        "    return data\n",
        "\n",
        "def play_annotation_from_df(row, margin: int = 0, samplerate = 50000):\n",
        "    \"\"\"Play a fragment of a wav file in a jupyter notebook.\n",
        "    Args:\n",
        "        row: a row of a pandas dataframe with the following columns:\n",
        "            - path: path to the wav file\n",
        "            - offset: offset in seconds\n",
        "            - duration: duration in seconds\n",
        "        margin: margin in seconds to add to the start and end of the fragment\n",
        "        samplerate: samplerate to use when reading the file\n",
        "        \"\"\"\n",
        "    m = margin * samplerate # margin in samples\n",
        "    start = max(int(np.floor(row['start'] - m)), 0)\n",
        "    #end = int(np.ceil(row['start'] + row['duration'] * samplerate + m))\n",
        "    end = row['end']\n",
        "    filename = row['path']\n",
        "    #print(row)\n",
        "    #print(filename)\n",
        "    play_audio_fragment(filename, start, end, samplerate)\n",
        "\n",
        "def export_annotation_from_df(row, margin: int = 0, samplerate = 50000):\n",
        "    \"\"\"Play a fragment of a wav file in a jupyter notebook.\n",
        "    Args:\n",
        "        row: a row of a pandas dataframe with the following columns:\n",
        "            - path: path to the wav file\n",
        "            - offset: offset in seconds\n",
        "            - duration: duration in seconds\n",
        "        margin: margin in seconds to add to the start and end of the fragment\n",
        "        samplerate: samplerate to use when reading the file\n",
        "        \"\"\"\n",
        "    m = margin * samplerate # margin in samples\n",
        "    start = max(int(np.floor(row['start'] - m)), 0)\n",
        "    end = int(np.ceil(row['start'] + row['duration'] * samplerate + m))\n",
        "    #end = int(np.ceil(row['end']))\n",
        "\n",
        "    iviend = row['end']\n",
        "    filename = row['path']\n",
        "\n",
        "    return export_audio_fragment(filename, start, end, iviend, samplerate)\n",
        "\n",
        "def export_noise(ruido, margin: int = 0, samplerate=50000):\n",
        "    m = margin * samplerate # margin in samples\n",
        "    start = max(int(np.floor(ruido.start - m)), 0)\n",
        "    end = int(np.ceil(ruido.start + ruido.duration * samplerate + m))\n",
        "    iviend = ruido.end\n",
        "    filename = ruido.path\n",
        "    return export_audio_fragment(filename, start, end, iviend, samplerate)\n",
        "\n",
        "\n",
        "dataset2 = pd.read_csv(\"./datathon2022\\\\datathon2022\\\\dataset1\\\\labels_dataset1_v2.csv\")\n",
        "\n",
        "\"\"\"\n",
        "noises es un archivo creado por nosotros luego de analizar manualmente los datos y encontrar momentos en los audios\n",
        "donde solo se escucha ruido.\n",
        "El objetivo de noises es crear una nueva clasificacion para distinguir ahora cuando un sonido es \"nothing\"\n",
        "\"\"\"\n",
        "\n",
        "noises = pd.read_csv(\"./datathon2022\\\\datathon2022\\\\dataset1\\\\noises.csv\")\n",
        "dataset2 = pd.concat([dataset2,noises], ignore_index = True)\n",
        "\n",
        "\n",
        "def f(signal, fs_rate = 50000, xi=0,xf=20000,yi=0):\n",
        "    \"\"\"\n",
        "    Esta funcion es para transformar la señal en forma de (amplitud(tiempo))\n",
        "    a amplitud(frecuencia)\n",
        "\n",
        "    Devuelve [freqs_side, FFT_side] -> en la primera componente están las frecuencias\n",
        "    y en la segunda componente las amplitudes.\n",
        "    \"\"\"\n",
        "\n",
        "    N = signal.shape[0]\n",
        "    secs = N / float(fs_rate)\n",
        "    Ts = 1.0/fs_rate # sampling interval in time\n",
        "    t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
        "    FFT = abs(fft(signal))\n",
        "    FFT_side = FFT[range(N//2)] # one side FFT range AMPLITUDES\n",
        "    freqs = scipy.fftpack.fftfreq(signal.size, t[1]-t[0])\n",
        "    freqs_side = freqs[range(N//2)] # one side frequency range FRECUENCIAS\n",
        "\n",
        "    return [freqs_side,FFT_side]\n",
        "\n",
        "def fgpu(signal,dataFFT):\n",
        "    \"\"\"\n",
        "    Mismo que f para gpu\n",
        "    \"\"\"\n",
        "\n",
        "    N = len(signal)\n",
        "    secs = N / 50000.0\n",
        "    Ts = 1.0/50000.0 # sampling interval in time\n",
        "    t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
        "\n",
        "    FFT = abs(dataFFT)\n",
        "\n",
        "\n",
        "    FFT_side = FFT[range(N//2)] # one side FFT range AMPLITUDES\n",
        "\n",
        "    freqs = scipy.fftpack.fftfreq(signal.size, t[1]-t[0])\n",
        "\n",
        "    freqs_side = freqs[range(N//2)] # one side frequency range FRECUENCIAS\n",
        "\n",
        "    return [freqs_side,FFT_side]\n",
        "\n",
        "\n",
        "def r(i):\n",
        "    \"\"\"\n",
        "    Funcion auxiliar para obtener la señal del audio.\n",
        "    \"\"\"\n",
        "    return export_annotation_from_df(dataset2.loc[i])\n",
        "def m(i,ds):\n",
        "    \"\"\"\n",
        "    Funcion auxiliar para obtener la señal del audio.\n",
        "    input:\n",
        "    \"\"\"\n",
        "    return export_annotation_from_df(ds.loc[i])\n",
        "\n",
        "\n",
        "def dato(K):\n",
        "    antes = time.time()\n",
        "    R = {}\n",
        "    size = 25000/5000\n",
        "    s = 0\n",
        "    e = {}\n",
        "    for i in range(0,5001):\n",
        "\n",
        "        for j in range(s,len(K[0])):\n",
        "            if K[0][j]<i*size:\n",
        "\n",
        "                if(i*size not in R):\n",
        "                    R[i*size] = []\n",
        "                R[i*size].append(K[1][j])\n",
        "            else:\n",
        "                s = j\n",
        "                break\n",
        "    for key,value in R.items():\n",
        "\n",
        "        e[key] = median(value)\n",
        "    print(\"demoro dato\",time.time()-antes)\n",
        "    return e\n",
        "\n",
        "\n",
        "def indexator(freqs):\n",
        "    size = len(freqs)\n",
        "    jump = size//1000\n",
        "    #print(size,jump)\n",
        "    I = [100,1000,3000,5000,12000,25000]\n",
        "    indexs = []\n",
        "    k = 0\n",
        "    for i in range(0,size,jump):\n",
        "        if k == 0:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                continue\n",
        "        if k == 1:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "        if k == 2:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "        if k == 3:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                continue\n",
        "        if k == 4:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                break\n",
        "    return indexs\n",
        "\n",
        "def indexator_noise(freqs):\n",
        "    size = len(freqs)\n",
        "    jump = size//1000\n",
        "    #print(size,jump)\n",
        "    I = [100,1000,3000,5000,12000,25000]\n",
        "    indexs = []\n",
        "    k = 0\n",
        "    for i in range(0,size,jump):\n",
        "        if k == 0:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                continue\n",
        "        if k == 1:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "        if k == 2:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "        if k == 3:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                continue\n",
        "        if k == 4:\n",
        "            if freqs[i] < I[k]:\n",
        "                continue\n",
        "            else:\n",
        "                indexs.append(i)\n",
        "                k+=1\n",
        "                break\n",
        "    return indexs\n",
        "\n",
        "\n",
        "def dato3(K):\n",
        "    freqs = K[0]\n",
        "    vals = K[1]\n",
        "    size = len(freqs)\n",
        "    partitions = indexator(K[0])\n",
        "    X = np.split(K[0],partitions)\n",
        "    Y = np.split(K[1],partitions)\n",
        "    return [X,Y]\n",
        "\n",
        "def dato4(K):\n",
        "    freqs = K[0]\n",
        "    vals = K[1]\n",
        "    neurons = 2508/6\n",
        "\n",
        "    R = []\n",
        "    PIVOT = 0\n",
        "    a = 0\n",
        "    sold=0\n",
        "    beg = False\n",
        "\n",
        "    jumps = [int(len(vals[s])/neurons) for s in range(0,6)]\n",
        "\n",
        "    for i in range(0,2508):\n",
        "        s = int(i//neurons)\n",
        "        if s != sold:\n",
        "            beg = True\n",
        "            a = 0\n",
        "        if (len(vals[s])<neurons):\n",
        "            R.append(np.median(vals[s]))\n",
        "            continue\n",
        "        jump = jumps[s]\n",
        "        if (jump == 0):\n",
        "            R.append(np.median(vals[s][a:a+1]))\n",
        "            a+=1\n",
        "            beg = True\n",
        "        else:\n",
        "            if(beg):\n",
        "                a = 0\n",
        "                beg = False\n",
        "            R.append(np.median(vals[s][a:a+jump]))\n",
        "            a += jump\n",
        "        sold = s\n",
        "    return R\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec41c623",
      "metadata": {
        "id": "ec41c623"
      },
      "outputs": [],
      "source": [
        "## BINARY SEARCH\n",
        "def binary_search_index(arr, val, start, end):\n",
        "    if end is None:\n",
        "        end = len(arr)-1\n",
        "    if start is None:\n",
        "        start = 0\n",
        "    if(arr[0] >= val):\n",
        "        return 0;\n",
        "    if(arr[len(arr)-1] <= val):\n",
        "        return len(arr)-1\n",
        "    while (start <= end):\n",
        "        mid = int((end+start)/2)\n",
        "        if (val >= arr[mid-1] and val <= arr[mid]):\n",
        "            if (abs(val-arr[mid-1]) < abs(val-arr[mid])):\n",
        "                return mid - 1\n",
        "            else:\n",
        "                return mid\n",
        "        else:\n",
        "            if (arr[mid]< val):\n",
        "                start = mid +1\n",
        "            else:\n",
        "                end = mid - 1\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5a9ecc",
      "metadata": {
        "id": "6f5a9ecc"
      },
      "outputs": [],
      "source": [
        "## FILTRO GENERICO\n",
        "\n",
        "def filterF(RF, signalF, reduction_fun,*args):\n",
        "    \"\"\"\n",
        "    Esta funcion implementa filtros genericos para ser aplicados a una señal en su forma de amplitud(frecuencia)\n",
        "    RF = Rango de frecuencias\n",
        "    signalF = [AMPLITUDES,FRECUENCIAS]\n",
        "    reduction_fun = función que lleva la lógica de como aplicar el filtro\n",
        "    \"\"\"\n",
        "\n",
        "    R = 6000\n",
        "    E = 8600\n",
        "    N = 1\n",
        "    k = 10\n",
        "    if(len(args) > 0):\n",
        "        R = args[0]\n",
        "    if(len(args) > 1):\n",
        "        N = args[1]\n",
        "    if(len(args) > 2):\n",
        "        E = args[2]\n",
        "    if(len(args) > 3):\n",
        "        k = args[3]\n",
        "\n",
        "    freq = signalF[0].copy()\n",
        "    amplitude = signalF[1].copy()\n",
        "    startFilter = RF[0]\n",
        "    endFilter = RF[1]\n",
        "\n",
        "    i_start = binary_search_index(freq, startFilter,0,len(freq))\n",
        "    i_end = binary_search_index(freq, endFilter,0,len(freq))\n",
        "\n",
        "    new_signal_amplitude = np.split(amplitude,[i_start,i_end])\n",
        "    new_signal_freq = np.split(freq,[i_start,i_end])\n",
        "\n",
        "    new_signal_amplitude[1] = reduction_fun(new_signal_freq[1],new_signal_amplitude[1],R,N,E,k)\n",
        "    new_signal = [freq,np.concatenate(new_signal_amplitude)]\n",
        "\n",
        "    return new_signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "262f4b55",
      "metadata": {
        "id": "262f4b55"
      },
      "outputs": [],
      "source": [
        "### FUNCIONES DE FILTRO\n",
        "\n",
        "def cancel(X,Y,*args):\n",
        "    \"\"\"\n",
        "    Funcion cancel, funcion constante 0\n",
        "    \"\"\"\n",
        "    for i in range(0,len(Y)):\n",
        "        Y[i] = 0\n",
        "    return Y\n",
        "\n",
        "def bandFilterSide(X,Y,R,n,*args):\n",
        "    \"\"\"\n",
        "    filtro de paso de banda superior\n",
        "    desde 0 Hz hasta R, reduce la amplitud con mas o menos amplitud según \"n\"\n",
        "    esto es para filtrar sonidos \"graves\"\n",
        "    \"\"\"\n",
        "    Y2 = Y.copy()\n",
        "\n",
        "    i = binary_search_index(X,R,0,len(X))\n",
        "\n",
        "\n",
        "    for j in range(0,i):\n",
        "        Y2[j] = Y2[j]*((X[j]/R)**n)\n",
        "    return Y2\n",
        "\n",
        "\n",
        "\n",
        "def bandFilter(X,Y,S,n,E,k,*args):\n",
        "    \"\"\"\n",
        "    filtro de\n",
        "    desde 0 Hz hasta R, reduce la amplitud con mas o menos amplitud según \"n\"\n",
        "    esto es para filtrar sonidos \"graves\"\n",
        "    \"\"\"\n",
        "    Y2 = Y.copy()\n",
        "\n",
        "    mid = S+((E-S)/2)\n",
        "    #print(mid)\n",
        "    i0 = binary_search_index(X,S,0,len(X))\n",
        "    imid = binary_search_index(X,mid,0,len(X))\n",
        "    i1 = binary_search_index(X,E,0,len(X))\n",
        "\n",
        "    #print(i0,imid,i1,n)\n",
        "\n",
        "    mx1 = max(Y2[i0:imid])\n",
        "    mx2 = max(Y2[imid:i1])\n",
        "\n",
        "    for j in range(i0,imid):\n",
        "        #Y2[j] = Y2[j]*((S/X[j])**N(Y2[j]))\n",
        "        Y2[j] = Y2[j]*((S/X[j])**(n*(1+k*(Y2[j]/mx1))))\n",
        "    for j in range(i1,imid):\n",
        "        #Y2[j] = Y2[j]*((X[j]/E)**decayRate(,))\n",
        "        Y2[j] = Y2[j]*((X[j]/E)**(n*(1+k*(Y2[j]/mx2))))\n",
        "\n",
        "    return Y2\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c5807bd",
      "metadata": {
        "id": "6c5807bd"
      },
      "outputs": [],
      "source": [
        "## LOAD RUIDO\n",
        "import noisereduce as nr\n",
        "class Ruido():\n",
        "    def __init__(self, path, start, end):\n",
        "        self.path = path\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.duration = end-start\n",
        "ruido = Ruido(\"1a6ade9060f77d67c56e96997036c339\", 187,192)\n",
        "noise = export_noise(ruido)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f789ae36",
      "metadata": {
        "id": "f789ae36"
      },
      "outputs": [],
      "source": [
        "todos = dataset2.query(\"label != 'volcano'\").sample(n=50)\n",
        "noise_indexs = dataset2.query(\"label == 'nothing'\")\n",
        "\n",
        "INPUT = pd.concat([todos,noise_indexs],ignore_index=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c66d99c",
      "metadata": {
        "scrolled": true,
        "id": "9c66d99c"
      },
      "outputs": [],
      "source": [
        "## PREPARAR X\n",
        "S = []\n",
        "c = 0\n",
        "for i in INPUT.index:\n",
        "    ##aplico filtros\n",
        "    print(\"voy por:\",c)\n",
        "    reduced = f(nr.reduce_noise(y=m(i,INPUT), y_noise=noise,sr = 50000))\n",
        "    filteredfreqSigNoise = filterF([0,24999], reduced, bandFilterSide,6000,1)\n",
        "    f_s8 = filterF([0,24999],filteredfreqSigNoise , bandFilter,7900,10,8600,10)\n",
        "    S.append(dato4(dato3(f_s8)))\n",
        "    c+=1\n",
        "\n",
        "X = []\n",
        "for s in S:\n",
        "    xx = []\n",
        "    for v in s:\n",
        "        xx.append(v)\n",
        "    X.append(xx)\n",
        "\n",
        "X_norm = []\n",
        "for i in range(0,len(X)):\n",
        "    mx = max(X[i])\n",
        "    arr = []\n",
        "    for xx in X[i]:\n",
        "        arr.append(xx/mx)\n",
        "    X_norm.append(arr)\n",
        "\n",
        "X_fit = np.array(X_norm)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40105ad5",
      "metadata": {
        "id": "40105ad5"
      },
      "outputs": [],
      "source": [
        "##PREPARAR Y\n",
        "Y = [INPUT.loc[i].label for i in INPUT.index]\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder =  LabelEncoder()\n",
        "y1 = encoder.fit_transform(Y)\n",
        "Y2 = pd.get_dummies(y1).values\n",
        "Y = Y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b215e56",
      "metadata": {
        "id": "8b215e56"
      },
      "outputs": [],
      "source": [
        "di = {}\n",
        "for i in INPUT.index:\n",
        "    if (INPUT.loc[i].label) in di:\n",
        "        di[INPUT.loc[i].label] += 1\n",
        "    else:\n",
        "        di[INPUT.loc[i].label] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315176c0",
      "metadata": {
        "scrolled": true,
        "id": "315176c0"
      },
      "outputs": [],
      "source": [
        "name_mapping = dict(zip(encoder.classes_,encoder.transform(encoder.classes_)))\n",
        "print(name_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45714e53",
      "metadata": {
        "id": "45714e53"
      },
      "outputs": [],
      "source": [
        "## from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "%load_ext tensorboard\n",
        "#strategy = tf.distribute.MirroredStrategy()\n",
        "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
        "\n",
        "#es = EarlyStopping(monitor='val_loss')\n",
        "mc = ModelCheckpoint('best_model-53.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "mc2 = ModelCheckpoint('best_model_acc-53.h5', monitor='accuracy', mode='max', save_best_only=True)\n",
        "# Define the checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Define the name of the checkpoint files.\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('\\nLearning rate for epoch {} is {}'.format(        epoch + 1, model.optimizer.lr.numpy()))\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs53'),\n",
        "    #mc,\n",
        "    #mc2,\n",
        "    PrintLR()\n",
        "]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fit, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(500,input_shape=(2508,), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(200, activation=\"relu\", ))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(100, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "###final layer\n",
        "model.add(Dense(4, activation=\"sigmoid\"))\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80a695d",
      "metadata": {
        "id": "e80a695d"
      },
      "outputs": [],
      "source": [
        "## ENTRENAMIENTO\n",
        "\n",
        "num_epochs = 1000\n",
        "num_batch_size = len(X_train)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=num_batch_size, epochs=num_epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=callbacks,\n",
        "          class_weight={0: 0.5, 1: 1, 2: 1, 3: 30, 4: 1},\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "153efb84",
      "metadata": {
        "id": "153efb84"
      },
      "outputs": [],
      "source": [
        "## FUNCIONES PARA PREPAPARAR EL SUBMIT\n",
        "\n",
        "SUBMISSION = [\n",
        "\"01767f8a26ee7958bdaad80f50f21873\", \"054f58f830e7c5285e5bada36c345303\", \"0550ebc7b63bd2c0a51c25418808c2da\", \"0723d88169bd201eb739d701b025c3f1\", \"09c5959a2ea99f9b627043e2c345d2c7\", \"0c0ddb1c5f6eff2ed61ab5981a2ecc76\", \"0cbd68f3e3b271d875bb6b4e785bed04\", \"17902ac9b47c468445535d977435719b\", \"1c870cba07b1721ce83d0230ad29ac27\", \"1ecdc73d4ede5054bc266027ee85717d\", \"2250b5d9c2b6f6ddc5ec7dd7a245f960\", \"25d6437b32bb9bebdea60d0a2d804256\", \"279d5a65213cfcaba3cc20f1732b4e46\", \"27c0e1ba4e990dfa577ef929ca980dde\", \"29cd6f1b944dff2e9fbd030a38227e77\", \"2cb1ea5bd6a54e30cc1f3f4e2eb345ce\",\"2dd9572b1b73cdeb22c8ef978fef116b\", \"2e9dc571f516a2cc9d9d0a55e77b2edb\", \"30f3144bd98625c9ceb96007b02f8d39\", \"350f50b5cfaab6db7e89e240b3dfa71b\", \"35daa1daee9e2c4ee6776b1e7ea30023\", \"3ab2c1e299a482e9e5639051f72e3666\", \"3b3d534ff9ecaa2d496384f395767de5\", \"40803725bd29a907eafc82a5e1cdc9d6\", \"51856fb8023427116b0f0280a2a6b3fa\", \"5314149fff2453dc0cf57782978fe9e8\", \"57df89f066013e817fde45e6cf85ad71\", \"57e2517e787cc132945f97e5624f592e\", \"5ea4440f4919807b232350b583df9a54\", \"5f366e2c54080751ad9a46c47ccd2835\", \"5f7f9862fe35358088ed897c7bb578e2\", \"64d2a1294e81aac4c5a8fb5e3c52036f\",\"672221d252ed82960addd82a47c3ffa7\", \"6752c7af5e42cd18b502f70073cd3f27\", \"6a94304dc4991087c738411d3eb4a4a4\", \"6d43df22bc5a6b65430bce36d5f2d38d\", \"6f0a1e5376f090bf052f0185d9999cc7\", \"73efa2618164520c0ae43eb17c7e8aa0\", \"7691e7a5c0a87603f46f9fd8a922f9ae\", \"7cb2bd0726ed980f5eafdf2aaae4c6c6\", \"829766a94ce6cdf7eaab0304573ad72d\", \"86d9de70af5d902e8ed0cb2dd995e06e\", \"8d60622fdfae997048cd16d100774fa0\", \"8d8bc83a4dbbc66aa5f5913ea5aece01\", \"94f88e5ca0865496e73461fd6ad00d7b\", \"9653e66ba82c221bcebf1ae9af87a29f\", \"97769c3b5d949a9a2d21bbfc71278bc4\", \"98201564e695dd198e92bf1f1d227412\",\"98f4029a330e7d4789b07a32b171b0a7\", \"9c06591c5fd08338dee65a876c954b06\", \"a338b5687352e577f741a9bdde1f4ddc\", \"ab3f0b439cd8ae0bf2d2085556387cdf\", \"b28b25611638b56ad3c57b1e8cf025bc\", \"b32980cab33f244299eeb2de68703953\", \"b6916f850a3625da9c263ee77b183bb2\", \"b7ef63086bef05d643b3dca386154996\", \"ba7a412feee5092fa4dc0483ecec7e06\", \"c553b6097deba92a34f95f27c257f0f9\", \"cab6299bbf433890f38126227c5e9408\", \"cb70f7e4770cde93b547be23b2ed25c3\", \"cea599fc01d1bce7cff6c12b5dd3fb28\", \"d11f5e776a688b322ffeab92798440c8\", \"d4c6ed2ec958c437589d72025ac68ce4\", \"dbc0921618293b53fa80a9b22765aa58\",\"dd093c40a9728812d278c80b04bb3586\", \"dfff14bc5caed74866586a57127beee0\", \"ebb37608fbe73d072485d4b447e91cab\", \"eccdfcc9573b2593c992a9147276d866\", \"f43b3951846402de1814e6d6d60e627e\", \"fb510a8dd4cf66a8f1e255a6085ab5c3\"\n",
        "]\n",
        "\n",
        "PATHS2 = [\"22fdfcd960203e6e18ab68988d00f3e9\",\"5a8e5cfdab183be547b06ec85d216acb\",\"7facf9dc202a4f85b05284f5b76bbdee\"]\n",
        "duration = 2\n",
        "def openAudio(filename):\n",
        "\n",
        "    #prefix = \"./datathon2022\\\\datathon2022\\\\dataset1\\\\\"\n",
        "    prefix = \"./datathon2022\\\\datathon2022\\\\dataset1\\\\submission\\\\\"\n",
        "    filename = f\"{prefix+filename}.wav\"\n",
        "    data, read_sr = sf.read(filename)\n",
        "    return data\n",
        "\n",
        "def partitionAudio(data, partitionSize, rate=50000):\n",
        "    totalFrames = len(data)\n",
        "    framesPerPartition = int(rate*partitionSize)\n",
        "    partitions = int(len(data)//framesPerPartition)\n",
        "    P = []\n",
        "    for i in range(0,partitions):\n",
        "        P.append(data[i*framesPerPartition:(i+1)*framesPerPartition])\n",
        "    return P\n",
        "\n",
        "def preprocessAudio(P):\n",
        "    PP = []\n",
        "    counter = 0\n",
        "    for signal in P:\n",
        "\n",
        "        reduced = f(nr.reduce_noise(y=signal, y_noise=noise,sr = 50000))\n",
        "        filteredfreqSigNoise = filterF([0,24999], reduced, bandFilterSide,6000,1)\n",
        "        f_s8 = filterF([0,24999],filteredfreqSigNoise , bandFilter,7900,10,8600,10)\n",
        "\n",
        "        s = dato4(dato3(f_s8))\n",
        "        xx = []\n",
        "        for v in s:\n",
        "            xx.append(v)\n",
        "        mx = max(xx)\n",
        "        arr = []\n",
        "        for kk in xx:\n",
        "            arr.append(kk/mx)\n",
        "        PP.append(arr)\n",
        "        counter+=1\n",
        "    return PP\n",
        "\n",
        "def modelPrediction(X,model):\n",
        "    predict_y = model.predict(X)\n",
        "    return predict_y\n",
        "\n",
        "\n",
        "class Prediction():\n",
        "    def __init__(self,path,start,end,label):\n",
        "        self.path = path\n",
        "        self.start = start\n",
        "        self.end = end\n",
        "        self.label = label\n",
        "\n",
        "    def print(self):\n",
        "        print(self.path, self.start, self.end, self.label)\n",
        "\n",
        "\n",
        "def clasiffy(path,predicted,res = duration):\n",
        "    clasificaciones = []\n",
        "    predic = predicted.copy()\n",
        "    for p in predic:\n",
        "        p[3]*=1\n",
        "    tt = np.argmax(predic,axis=1)\n",
        "    paths = []\n",
        "    starts = []\n",
        "    ends = []\n",
        "    labels = []\n",
        "    for t in range(0,len(tt)):\n",
        "        if tt[t] == 0:\n",
        "            clasificaciones.append(Prediction(path,t*res,(t+1)*res,\"allfreq\"))\n",
        "            paths.append(path)\n",
        "            starts.append(t*res)\n",
        "            ends.append((t+1)*res)\n",
        "            labels.append(\"allfreq\")\n",
        "        elif tt[t] == 1:\n",
        "            clasificaciones.append(Prediction(path,t*res,(t+1)*res,\"cetaceans_allfreq\"))\n",
        "            paths.append(path)\n",
        "            starts.append(t*res)\n",
        "            ends.append((t+1)*res)\n",
        "            labels.append(\"cetaceans_allfreq\")\n",
        "        elif tt[t] == 2:\n",
        "            clasificaciones.append(Prediction(path,t*res,(t+1)*res,\"click\"))\n",
        "            paths.append(path)\n",
        "            starts.append(t*res)\n",
        "            ends.append((t+1)*res)\n",
        "            labels.append(\"click\")\n",
        "        elif tt[t] == 3:\n",
        "            continue\n",
        "        elif tt[t] == 4:\n",
        "            clasificaciones.append(Prediction(path,t*res,(t+1)*res,\"whistle\"))\n",
        "            paths.append(path)\n",
        "            starts.append(t*res)\n",
        "            ends.append((t+1)*res)\n",
        "            labels.append(\"whistle\")\n",
        "    pred = pd.DataFrame({\n",
        "        \"path\":paths,\n",
        "        \"start\":starts,\n",
        "        \"end\":ends,\n",
        "        \"label\": labels\n",
        "    })\n",
        "\n",
        "\n",
        "    return pred\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6b0dad3",
      "metadata": {
        "id": "f6b0dad3"
      },
      "outputs": [],
      "source": [
        "name_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0caff6",
      "metadata": {
        "id": "8b0caff6"
      },
      "outputs": [],
      "source": [
        "DATAS4 = []\n",
        "counter = 1\n",
        "for audio in PATHS2:\n",
        "    print(\"Voy por el:\",counter)\n",
        "    oppened = openAudio(audio)\n",
        "    partitions = partitionAudio(oppened,duration)\n",
        "    processed = preprocessAudio(partitions)\n",
        "    DATAS4.append((audio,processed))\n",
        "    counter+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e847d2",
      "metadata": {
        "id": "e0e847d2"
      },
      "outputs": [],
      "source": [
        "PREDICCIONES = []\n",
        "from keras.models import load_model\n",
        "model_for_prediction = load_model(\"ultimo6.h5\")\n",
        "counter = 0\n",
        "for audio in SUBMISSION:\n",
        "    print(\"Voy por el:\",counter)\n",
        "    oppened = openAudio(audio)\n",
        "    partitions = partitionAudio(oppened,duration)\n",
        "    processed = preprocessAudio(partitions)\n",
        "    predicted = modelPrediction(processed,model_for_prediction)\n",
        "    pred = clasiffy(audio,predicted)\n",
        "    PREDICCIONES.append(pred)\n",
        "    counter+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35d607a",
      "metadata": {
        "id": "f35d607a"
      },
      "outputs": [],
      "source": [
        "final2 = pd.concat(PREDICCIONES,ignore_index=True)\n",
        "final2.to_csv('pred.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f9e072",
      "metadata": {
        "id": "50f9e072"
      },
      "outputs": [],
      "source": [
        "import sed_eval\n",
        "def transform_to_sed_dataset(df):\n",
        "    df = df.copy()\n",
        "    df[\"file\"] = df.path\n",
        "    df.start = df.start.astype(float)\n",
        "    df.end = df.end.astype(float)\n",
        "    df_dicts = df.rename(columns={\n",
        "              \"path\":\"scene_label\",\n",
        "              \"start\":\"event_onset\",\n",
        "              \"end\":\"event_offset\",\n",
        "              \"label\":\"event_label\"\n",
        "          }).to_dict(\"records\")\n",
        "    return df_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec23eb40",
      "metadata": {
        "id": "ec23eb40"
      },
      "outputs": [],
      "source": [
        "evaluator = sed_eval.sound_event.SegmentBasedMetrics(\n",
        "    # volcano no se considera en la evaluación\n",
        "    ['whistle', 'cetaceans_allfreq', 'click', 'allfreq'],\n",
        "    time_resolution=0.1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d37c7f",
      "metadata": {
        "id": "58d37c7f"
      },
      "outputs": [],
      "source": [
        "evaluator.evaluate(\n",
        "    reference_event_list=transform_to_sed_dataset(test),\n",
        "    estimated_event_list=transform_to_sed_dataset(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46df3a3d",
      "metadata": {
        "id": "46df3a3d"
      },
      "outputs": [],
      "source": [
        "evaluator.results_overall_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757333ac",
      "metadata": {
        "id": "757333ac"
      },
      "outputs": [],
      "source": [
        "print(evaluator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4f2096",
      "metadata": {
        "id": "cd4f2096"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a833d3a",
      "metadata": {
        "id": "3a833d3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a973fc",
      "metadata": {
        "id": "56a973fc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}